---
title: "Historical MAL dataset cleanup"
author: "Edward Yu"
date: "December 07, 2018"
output:
  # pdf_document:
  #     toc: true
  #     toc_depth: 2
  #     df_print: kable
  #     citation_package: natbib
  html_document:
      theme: flatly
      highlight: tango
      toc: true
      toc_float:
        collapsed: true
      toc_depth: 3
      df_print: paged
      code_folding: show
      # fig_width: 7
      # fig_height: 6
      # fig_caption: true
      # citation_package: natbib
# bibliography: bib.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo    = TRUE,
                      error   = FALSE,
                      message = FALSE,
                      warning = FALSE)

if(!require(tidyverse)) install.packages("tidyverse")
library(tidyverse)
if(!require(gridExtra)) install.packages("gridExtra")
library(gridExtra)
if(!require(naniar)) install.packages("naniar")
library(naniar) # gg_miss
if(!require(stringdist)) install.packages("stringdist")
library(stringdist) # soundex?
if(!require(phonics)) install.packages("phonics")
library(phonics) # soundex?
if(!require(lexicon)) install.packages("lexicon")
library(lexicon) # common_names
if(!require(xlsx)) install.packages("xlsx")
library(xlsx)
if (!require(viridis)) install.packages("viridis")
library(viridis)

rm(list=ls())
setwd("D:/Code/R/historical.MAL")
```

# Introduction
## *From Marek*: 
### If you are interested...
I have a small project for R, which is very useful. It has to do with history records of MAL. Here is some basic info:
  
  * Goal: Clean up and consolidate dataset to enable easy searching of past melt
records
  * Tasks: 
    + Mostly working with strings removing duplicates ( E. Yu, YU, Yu Edward …)
    + Removing empty records
    + Missing data
    + Multiple variables in one column
  
There might be other things to do but I have not spent much time looking at the dataset. We could also pull some basic stats on usage, costs, repeats etc. I don’t know your skill level, but it is relatively simple project and I am estimating it would take me about 8 hrs of work. Actual coding, if you know what to use, could be done in less than 1 hour but that requires proficiency in typing and in R.  

I just noticed that sand for this year should have all been W410, excel incremented the name by 1 each time. I think I might be adding information about individual tests from this year incrementally as it comes in and since it is only several rows, perhaps you can delete the entire set of rows from this year, if that makes things easier on your end.

# Load & peak data
## Import data
```{r}
x <- read_csv("data/History.csv")
glimpse(x)
```

## Check levels
```{r}
# create function for later use
get_levels <- function(df, col){
  x.levels <- cbind(colnames(df),
                    (as.data.frame(sapply(df,function(x) length(unique(x)))))
  )
  colnames(x.levels) <- c("var","levels")
  row.names(x.levels) <- NULL
  levels <- x.levels[order(-x.levels[,2]),]
  return(levels[col,])
}
get_levels(x)
```

## Peak missing values
```{r}
gg_miss_var(x, show_pct = T)
gg_miss_which(x)
```

## Outline of actions to take
Rename variables to be all lowercase with no spaces. Seems the most important variables are casting type and alloy type, as these are the only with zero missing values.

 * **Request**: should have 3,629 levels
 * **ID**: not utilized in recent pours, delete
 
 * **Date received**: convert to date format, fill missing values, for some reason there are less dates received than dates completed
 * **Date poured**: convert to date format, fill missing values
 * **Date completed**: convert to date format, fill missing values, perhaps create new column calculating days to complete from date received/completed
 
 * **Notes ML**: NA
 * **Special projects**: most values are missing, unsure of importance of this field, should likely merge with comments or remove entirely  
 
 * **Requested by**: fill missing values, will require some renaming/matching
 * **Customer name**: fill missing values, will require some renaming/matching
 * **Product tested**: fill missing values, will require some renaming/matching
 
 * **Alloy**: NA
 * **Casting type**: NA
 * **Number of castings**: some NA values, fill in with rounded averages 
 * **lbs**: lbs of metal used, could be calculated based on values,  fill missing values
 
 * **Sand type**: fill missing values, will require some renaming/matching
 * **Amount used**: sand? unsure what amount this is talking about
 
 * **Furnace cycle**: need to come up with new way to ID new lining and cycles

 * **Total hours**: many NA values, should be calculated automatically based on number of castings, casting type, etc
 * **Total cost**: fill missing values, perhaps determine how it is calculated to automate the calculation
 
We have many missing datapoints, fields that aren't inuitive, some useless fields, fields that need added, etc. We'll start with the most simple and move on.  

# Cleaning
## Rename columns
Convert column names to lower case, replace spaces with periods.  
```{r}
names <- tolower(colnames(x))    # convert to lowercase
names <- gsub("  ", " ", names)  # remove double spaces
names <- gsub(" ", "\\.", names) # replace space with .
names[c(12,14)] <- c("alloy.lbs", "sand.lbs")
colnames(x) <- names
colnames(x)
```

## $request
There is a duplicate entry somewhere based on number of unique levels versus number of rows.
```{r}
which(duplicated(x$request)==TRUE)
as.data.frame(t(x[3609:3611,]))
```

The first entry appears to have been made in error until we see the furnace cycle was incremented. Probably shouldn't remove, will simply re-assign all request variables to equal row numbers.  
```{r}
x <- x %>% 
  mutate(request = seq(1:nrow(x)))
get_levels(x, 1)
```
 
## $id
Delete useless column.
```{r}
x <- x %>% 
  select(-id)
```

## Convert dates, add lead time
Convert char to date values.  
```{r}
x <- x %>% 
  mutate(date.poured = as.Date(x$date.poured, "%m/%d/%Y")) %>% 
  mutate(date.received = as.Date(x$date.received, "%m/%d/%Y")) %>% 
  mutate(date.completed = as.Date(x$date.completed, "%m/%d/%Y"))

summary(x[c(3,2,4)])
```

With these dates we can now determine a few useful values:

  * Preprocessing time: date poured - date recieved
  * Postprocessing time: date complete - date poured
  * Lead time: date complete - date received  
  
Of course, we need to fix the erroneous entries that are pushing our `Max` values all the way up to the year 2513.

### Fix far future dates
We manually fix the handful of dates with typos.  

```{r}
wrong.dates <- x %>% 
  filter(date.received  > "2020-01-01" |
         date.poured    > "2020-01-01" | 
         date.completed > "2020-01-01")
as.data.frame(wrong.dates)[,c(1,3,2,4)]

# manually fix
x$date.poured[1103]    <- as.Date("2002-04-30")
x$date.completed[1198] <- as.Date("2002-08-22")
x$date.received[1889]  <- as.Date("2005-11-17")
x$date.poured[2735]    <- as.Date("2002-06-10")
x$date.received[2740]  <- as.Date("2010-06-15")
x$date.received[3106]  <- as.Date("2012-03-20")
x$date.received[3149]  <- as.Date("2012-06-19")
x$date.received[3341]  <- as.Date("2013-11-01")
x$date.completed[3582] <- as.Date("2016-04-05")
x$date.poured[3606]    <- as.Date("2017-08-24")

# dates now seem to be in a normal range
summary(x[c(3,2,4)])
```

### Calculate lead times
Now that are values are all within somewhat normal ranges, detecting further errors will require calculating the differences in dates. For example if `date.received` has a later date than `date.completed` we will see a negative value in our new `lead.time` variable.  

Using the function on our current data shows negative values in all new variables as well as some unrealistically large `Max` values.

```{r}
## create function so that results of editing can be seen quickly
calc_lead <- function(){
  preprocessing.time  <- as.numeric(x$date.poured-x$date.received)
  postprocessing.time <- as.numeric(x$date.completed-x$date.poured)
  lead.time           <- preprocessing.time + postprocessing.time
  x.temp <- as_tibble(cbind(x,
                            preprocessing.time,
                            postprocessing.time,
                            lead.time))
  return(x.temp)
}

summary(calc_lead()[c(19:21)])
```

### Fix large processing values
We filter for values larger than 400 and find quite a few entries have simple typos. We correct the handful of errors by hand.  

```{r}
## fix large values
wrong.dates <- calc_lead() %>% 
  filter(preprocessing.time > 400 |
           postprocessing.time > 400)
wrong.dates[c(1,3,2,4)]

# manually fix
x$date.received[310]  <- as.Date("1999-10-20")
x$date.poured[930]    <- as.Date("2001-08-30")
x$date.poured[1091]   <- as.Date("2002-04-22")
x$date.received[1616] <- as.Date("2004-04-13")
x$date.poured[1668]   <- as.Date("2004-08-04")
x$date.poured[1877]   <- as.Date("2005-11-01")
x$date.received[2229] <- as.Date("2007-01-07")
x$date.poured[2735]   <- as.Date("2010-06-10")
x$date.poured[3133]   <- as.Date("2012-05-17")

# max values look better now
summary(calc_lead()[c(19:21)])
```

### Fix negative processing values
This occurs when dates are not in proper chronology: date.received < date.poured < date.completed. We can fix this by filtering for dates that do not meet this criteria and adjusting them based on available dates and median values for preprocessing/postprocessing/lead times.  

In this case we have 244 rows of incorrectly ordered data, definitely not going to do this manually. This time we'll impute the missing data by taking the median values of the correct data. First part of the code fixes NA values.  

```{r}
# fix negatives
# must follow: received < poured < completed
wrong.dates2 <- calc_lead() %>% 
  filter(preprocessing.time < 0 | postprocessing.time < 0)
wrong.dates2[c(1,3,2,4)]

# antijoin the incorrect data
x.anti <- anti_join(calc_lead(), wrong.dates2, c("request"))

# record median values for imputation
summary(x.anti[c(19:21)])
# preprocessing.time postprocessing.time   lead.time     
# Median :  6.000    Median :  3.000     Median :  9.00  

# have NA values in date.completed
summary(wrong.dates2[c(3,2,4)])

# if NA change completed date to received + 9
for (i in 1:dim(wrong.dates2)[1]){
  if (is.na(wrong.dates2$date.completed[[i]]) == TRUE){
    wrong.dates2$date.completed[[i]] <- wrong.dates2$date.received[[i]] + 9
  }
}

# no more NA's
summary(wrong.dates2[c(3,2,4)])

#
# now we fix errors in chronology causing negative time calculations
summary(wrong.dates2[c(19:21)])

# start with received coming before poured
# wrong.dates2$date.received > wrong.dates2$date.poured
wrong.dates2[c(2,3,6,7),c(3,2,4)]

# then completed coming before poured
# wrong.dates2$date.poured > wrong.dates2$date.completed
# wrong.dates2$date.completed < wrong.dates2$date.poured
wrong.dates2[c(1,4,5,8),c(3,2,4)]

for (i in 1:dim(wrong.dates2)[1]){
  # preprocessing time = poured - received; median = 6
  if (wrong.dates2$date.received[[i]] > wrong.dates2$date.poured[[i]]){
    wrong.dates2$date.received[[i]] <- wrong.dates2$date.poured[[i]] - 6
  }
  # postprocessing time = completed - poured; median = 3
  if (wrong.dates2$date.completed[[i]] < wrong.dates2$date.poured[[i]]){
    wrong.dates2$date.completed[[i]] <- wrong.dates2$date.poured[[i]] + 3
  }
}

# confirm chronology
# wrong.dates2$date.received <= wrong.dates2$date.poured
# wrong.dates2$date.poured <= wrong.dates2$date.completed

# now that `wrong.dates2` has corrected values, merge with original df
counter=1
for (i in 1:nrow(x)){
  if (counter == nrow(wrong.dates)+1){break}
  if (x$request[[i]] == wrong.dates$request[[counter]]){
    x[i,c(2,3,4)] <- wrong.dates[counter,c(2,3,4)]
    counter=counter+1
  }
}

# date summary looks okay now... except for NA's
summary(calc_lead()[c(19:21)])
```

### Fix NA values in dates
Our calculations have NA values which means our dates must have NA's. We'll check which date columns contain NA's and in a similar fashion to above will impute appropriate dates based on the calculated median values above.  

Based on the `summary` output it looks like `date.poured` has only a single `NA` value. If we fill this date in by hand we can just calculate the other variables based on the `date.poured` value and our previously calculated median values of processing times.  

```{r}
# check NAs
summary(x)[,c(3,2,4)]

# fill NA values using date.poured to calculate received and completed
# guess on single NA
x %>% filter(is.na(date.poured))
(x[3608:3612,])
(x$date.poured[3611] - x$date.poured[3609]) / 2 # 144 days between dates
# just assign the middle date
x$date.poured[3610] <- x$date.poured[3609] - 72

# now date.poured has no NA's and we can extrapolate from this
summary(x)[,c(3,2,4)]

# convert all NA date.received to date.poured-6
x.rec <- x %>% 
  filter(is.na(date.received)) %>% 
  mutate(date.received = date.poured - 6)

# merge back into original df
counter=1
for (i in 1:nrow(x)){
  if (x$request[[i]] == x.rec$request[[counter]]){
    x[i,c(2,3,4)] <- x.rec[counter,c(2,3,4)]
    counter=counter+1
  }
}

# convert all NA date.completed to date.poured+6
x.com <- x %>% 
  filter(is.na(date.completed)) %>% 
  mutate(date.completed = date.poured + 3)

# merge back into original df
counter=1
for (i in 1:nrow(x)){
  if (x$request[[i]] == x.com$request[[counter]]){
    x[i,c(2,3,4)] <- x.com[counter,c(2,3,4)]
    counter=counter+1
  }
}

# NOW we have zero NA values
summary(calc_lead()[c(19:21)])

# assign our new values to the df
x <- calc_lead()
```

## $special.projects
Seems to be a redundant column when the $notes column would suffice. Check if values are stored in the column and concatenate them with the notes column.  
```{r}
# list non-NA values in special projects
x$special.projects[!is.na(x$special.projects)]

# find rownums of non-NA vlaues
spec.rows <- which(!is.na(x$special.projects)==T)

# check notes.ml of same rownums
x$notes.ml[spec.rows]

# concatenate the columns
x[spec.rows,] <- x[spec.rows,] %>%
  mutate(notes.ml = paste(notes.ml, special.projects, sep="--"))

# confirm
x$notes.ml[spec.rows]
```

## $requested.by
Remove duplicate and misspelled names.

```{r}
# remove double spaces, commas, periods, caps, generate soundex
x <- x %>%
  mutate(requested.by = str_replace_all(requested.by, '\\  ', '')) %>% 
  mutate(requested.by = str_replace_all(requested.by, '\\,', '')) %>% 
  mutate(requested.by = str_replace_all(requested.by, '\\.', '')) %>% 
  mutate(requested.by = str_to_lower(requested.by)) %>% 
  mutate(sound = soundex(requested.by,clean=F))

# list unique sounds
unique(x$sound)

# find problem rows: 1,540,3484
x %>% 
  filter(sound == "" | is.na(sound))

# check surrounding rows
x[c(1:3,539:542,3483:3485),c(1,5,22)]

# replace NA/number values with next name in line
x$requested.by[c(1,540,3484)] <- x$requested.by[c(2,541,3485)]

# unique names and sounds
length(unique(x$requested.by)) # 204 unique names
length(unique(x$sound))        # 132 unique sounds
```

We can see that we have quite a few unique names with less unique sounds. This might be because some names are misspelled and the misspellings don't change the sounds of the names. To address this we'll loop through each unique name, then take the sound of that name, grouped with all other names that have the same sound. Using this subset that all shares the same sound, we can sort the names in descending order, choosing the most popular and replacing all names by this most popular one.  We'll see this reduces the amount of unique names fom 204 to 132: the same value of unique sounds.

```{r}
unique.names <- unique(x$sound)
# some names are misspelled but have the same sound
# replace any same-sounding with top used name
# replace unique name with most popular unique name filtered by sound
for (i in 1:length(unique.names)){
  # find most popular name of same sounding names
  replacement.name <- x %>% 
    filter(sound == unique.names[[i]]) %>%
    group_by(requested.by) %>% 
    summarise(count=n()) %>% 
    arrange(desc(count))
  replacement.name <- replacement.name[[1]][1]
  # if unique.name == requestor$sound, replace with replacement.name
  x$requested.by[x$sound == unique.names[[i]]] <- 
    replacement.name
}

# 129 unique names now
length(unique(x$requested.by)) 
```

Though we're in a better place, we still see mispelled names in our data. Not much choice but to manually sift through and decide which names should be replaced by what. After manual replacement, our total unique names dips again to 106 from 129.  

```{r}
# but we see mispellings such as adamotvits or lowek
unique(x$requested.by)

# not many options but to skim thru manually
name.levels <- as.data.frame(table(x$requested.by))
name.levels

x <- x %>% 
  mutate(requested.by.tf = requested.by) %>%
  mutate(requested.by.tf = ifelse(grepl('vits',requested.by), "mark adamovits", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('bald',requested.by), "jim archibald", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('heid',requested.by), "ron aufderheide", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('carr',requested.by), "ben carr", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('yu',requested.by), "edward yu", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('tain',requested.by), "gerry fountaine", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('herr',requested.by), "henry c", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('henr',requested.by), "henry c", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('igel',requested.by), "judy rigel", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('lowe',requested.by), "kathy lowe", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('vivas',requested.by), "paula vivas", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('lund',requested.by), "m skoglund", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('showm',requested.by), "ralph showman", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('wang',requested.by), "xianping wang", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('hart',requested.by), "matt hartman", requested.by.tf)) %>%
  mutate(requested.by.tf = ifelse(grepl('yeom',requested.by), "n yeomans", requested.by.tf)) %>% 
  mutate(requested.by = requested.by.tf) %>% 
  select(-requested.by.tf)

# check length again
length(unique(x$requested.by)) # 106
# seems to be good enough
unique(x$requested.by)
```

## $customer.name
```{r}
# only 2 missing customer names, replace with ASK
x %>%
  filter(is.na(x$customer.name)==TRUE)
x$customer.name[c(3366,3377)] <- "ASK"
```

## $alloy
We perform pretty much the same actions as we did above, with `requested.by`.

```{r}
unique(x$alloy)
length(unique(x$alloy)) # 60

# convert case, remove punctuations
x <- x %>%
  mutate(alloy = str_replace_all(alloy, '\\  ', '')) %>% 
  mutate(alloy = str_replace_all(alloy, '\\,', '')) %>% 
  mutate(alloy = str_replace_all(alloy, '\\.', '')) %>% 
  mutate(alloy = str_to_lower(   alloy))

length(unique(x$alloy)) # 47

x <- x %>% 
  mutate(alloy.new = alloy) %>%
  mutate(alloy.new = str_replace_all(alloy.new, "[:punct:]","none")) %>% 
  mutate(alloy.new = ifelse(grepl('al',alloy), "aluminum", alloy.new)) %>% 
  mutate(alloy.new = ifelse(grepl('di',alloy),      "ductile iron", alloy.new)) %>% 
  mutate(alloy.new = ifelse(grepl('ductile',alloy), "ductile iron", alloy.new)) %>%
  mutate(alloy.new = ifelse(grepl('le iron',alloy), "ductile iron", alloy.new)) %>% 
  mutate(alloy.new = ifelse(grepl('gray',alloy),   "grey iron", alloy.new)) %>% 
  mutate(alloy.new = ifelse(grepl('y iron',alloy), "grey iron", alloy.new)) %>% 
  mutate(alloy.new = ifelse(grepl('cg',alloy), "cgi", alloy.new)) %>% 
  mutate(alloy.new = ifelse(grepl('brass',alloy), "bras", alloy.new)) %>% 
  mutate(alloy.new = ifelse(grepl('s steel',alloy), "stainless", alloy.new)) %>%
  mutate(alloy.new = ifelse(grepl('44',alloy),      "stainless", alloy.new)) %>%
  mutate(alloy.new = ifelse(grepl('ss',alloy),      "stainless", alloy.new)) %>%
  mutate(alloy.new = ifelse(grepl('teel',alloy), "lc steel", alloy.new)) %>% 
  mutate(alloy.new = ifelse(grepl('bras',alloy), "brass", alloy.new)) %>% 
  mutate(alloy.new = ifelse(alloy.new == "0" | 
                              alloy.new == "none" | 
                              alloy.new == "unknown", NA, alloy.new)) %>% 
  mutate(alloy = alloy.new) %>% 
  select(-alloy.new)

# confirm
unique(x$alloy)
length(unique(x$alloy)) # 11
```

## $furnace.cycle
This datapoint kept track of how many uses each furnace lining accumulated. Instead of using continuing with this way of measuring where we increment each number, we'll split the measure into two columns: one representing the furnace liner, the other representing how many pours it lasted.   

First, we assign `NA` to all furnace values with alloys of aluminum as aluminum uses a different furnace. We then create a few new columns, the first of which is `furnace` and will represent the furnace lining being used; `furnace cycle` will increment with each use of the `furnace`; and `furnace.name` will be a more endearing name given to the furnace.   

```{r}
# since aluminum uses a different furnace, change all to NA
x$furnace.cycle[x$alloy=="aluminum"] <- NA

# test df
# select first letter to call furnace
xx <- x %>% 
  select(request, furnace.cycle, alloy) %>% 
  filter(alloy != "aluminum") %>% 
  mutate(furnace = str_sub(furnace.cycle,1,1)) %>% 
  mutate(furnace = str_to_lower(furnace)) %>% 
  mutate(cycle = NA) %>% 
  mutate(furnace.name = NA)

# some NA values
xx[is.na(xx$furnace.cycle),]

# if NA, pull value above
for (i in 1:nrow(xx)){
  if (is.na(xx$furnace[[i]])){
    xx$furnace[[i]] <- xx$furnace[[i-1]]
  }
}

# zeros confused with letter o
xx[1543:1576,]
# replace zeros with o's
xx[xx$furnace==0,][4] <- "o"

# M between L's
xx[2679:2684,]
xx[xx$request==3468,][4] <- "m"

# O between N's
xx[2725:2729,]
# switch place
which(xx$request==3517) # 2726
xx[2726,][1] <- 3518
xx[2727,][1] <- 3517
# rearrange rows
xx <- xx %>% 
  arrange(request)

# increment furnace cycle if furnace before = furnace current
# if not, assign value = 1
cycle.counter=1
for (i in 2:nrow(xx)){
  # first row = 1
  xx$cycle[[1]] <- 1
  # vars 
  before =  i-1
  current = i
  # current != before, start counter over
  if (xx$furnace[[current]] != xx$furnace[[before]]){
    cycle.counter=1
    xx$cycle[[current]] <- cycle.counter
  }
  if (xx$furnace[[current]] == xx$furnace[[before]]){
    cycle.counter=cycle.counter+1
    xx$cycle[[current]] <- cycle.counter
  }
}

# load names to assign to furnaces, shuffle them
data("common_names")
names <- common_names[1:length(common_names)]
set.seed(1111)
names <- sample(names)

# assign names instead of letters to each furnace
name.counter = 0
for (i in 1:nrow(xx)){
  if (xx$cycle[[i]] == 1){
    name.counter=name.counter+1
    xx$furnace.name[[i]] <- names[[name.counter]]
  }
  if (xx$cycle[[i]] != 1){
    xx$furnace.name[[i]] <- names[[name.counter]]
  }
}

# rejoin data
x <- full_join(x,xx)
```

## $casting.type
There are quite a few different kinds of castings. I've manually gone thru and renamed a few, it seems an improvement.

```{r}
# way too many unique
unique(x$casting.type)
length(unique(x$casting.type)) # 274

# remove double spaces, commas, periods
x <- x %>%
  mutate(casting.type1 = str_replace_all(casting.type, '\\  ', ' ')) %>% 
  mutate(casting.type1 = str_replace_all(casting.type, '\\,', ' ')) %>%
  mutate(casting.type1 = str_replace_all(casting.type, '\\.', ' ')) %>%
  mutate(casting.type1 = str_to_lower(   casting.type)) %>% 
  mutate(casting.type = casting.type1) %>% 
  select(-casting.type1)

# unique(x$casting.type)
length(unique(x$casting.type)) # 264

x <- x %>% 
  mutate(casting.type1 = casting.type) %>%
  mutate(casting.type1 = ifelse(grepl('cube',casting.type), "shrink cube", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('ero',casting.type), "erosion wedge", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('sleeve',casting.type), "sleeves", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('shake',casting.type), "shakeout tree", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('page',casting.type), "warpage block", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('ration',casting.type), "penetration", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('pene',casting.type), "penetration", casting.type1)) %>%
  mutate(casting.type1 = ifelse(grepl('graphit',casting.type), "graphite step", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('cone',casting.type), "stepcone", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('steps',casting.type), "stepcone", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('graphite',casting.type), "graphite stepcones", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('fluid',casting.type), "fluidity spiral", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('buck',casting.type), "belt buckles", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('gator',casting.type), "gator", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('soot p',casting.type), "sootplate", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('gear',casting.type), "gear mold", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('rotor',casting.type), "brake rotor", casting.type1)) %>% 
  mutate(casting.type1 = ifelse(grepl('pig',casting.type), "pigs", casting.type1)) %>%
  mutate(casting.type1 = ifelse(grepl('impel',casting.type), "di impeller", casting.type1)) %>% 
  mutate(casting.type = casting.type1) %>% 
  select(-casting.type1)

# slightly better, not perfect
unique(x$casting.type)
length(unique(x$casting.type)) # 120
```

## $sand.type
Not the most important variable, will change a few of the obvious errors.  

```{r}
unique(x$sand.type)
length(unique(x$sand.type)) # 113

x <- x %>%
  mutate(sand.type1 = str_replace_all(sand.type, '\\ ', ' ')) %>% 
  mutate(sand.type1 = str_replace_all(sand.type, '\\,', ' ')) %>% 
  mutate(sand.type1 = str_replace_all(sand.type, '\\.', ' ')) %>% 
  mutate(sand.type1 = str_to_lower(   sand.type)) %>% 
  mutate(sand.type = sand.type1) %>% 
  select(-sand.type1)

# unique(x$sand.type)
length(unique(x$sand.type)) # 111

x <- x %>%
  mutate(sand.type1 = sand.type) %>%
  mutate(sand.type1 = ifelse(grepl('w41',sand.type), "w410", sand.type1)) %>% 
  mutate(sand.type = sand.type1) %>%
  select(-sand.type1)

# unique(x$sand.type)
length(unique(x$sand.type)) # 102
```

## Finalize, reorder variables
We've done enough cleaning for some analysis, will reorder some variables for more clear presentation and change some column classes. The final dataframe will be renamed `y` instead of `x` and exported to a new file.. 

```{r}
################################
y <- x %>% 
  select(request,
         date.received,
         date.poured,
         date.completed,
         requested.by,
         customer.name,
         product.tested,
         casting.type,
         number.of.castings,
         alloy,
         alloy.lbs,
         sand.type,
         sand.lbs,
         total.hours,
         total.cost,
         preprocessing.time,
         postprocessing.time,
         lead.time,
         furnace.name,
         cycle,
         notes.ml) %>% 
  mutate(requested.by=as.factor(requested.by)) %>% 
  mutate(customer.name=as.factor(customer.name)) %>% 
  mutate(product.tested=as.factor(product.tested)) %>% 
  mutate(casting.type=as.factor(casting.type)) %>% 
  mutate(alloy=as.factor(alloy)) %>% 
  mutate(sand.type=as.factor(sand.type)) %>% 
  mutate(furnace.name=as.factor(furnace.name)) 

gg_miss_var(y, show_pct = T)
glimpse(y)

# export to xls
write.xlsx(y, file=paste0(getwd(),"/data/cleanedMAL.xlsx"), sheetName="Sheet1", 
           col.names=TRUE, row.names=TRUE, append=FALSE)
```

# Analysis
Now we need to figure out what to do with the data. First we can try some simple EDA with what variables we have, then get into analysis more focused on furnace life.  

## EDA
A couple basic plots show our busiest months occur between August and May, and that pour frequency has reduced dramatically since 1999, or even 2015 for that matter.   


```{r}
# Histogram of pours per month
g1 <- y %>% 
  mutate(month=as.factor(substring(months.Date(x$date.poured),1,3))) %>% 
  ggplot(aes(x=month,fill=..count..))+
  geom_histogram(stat="count")+
  scale_x_discrete(limits=c("Jan","Feb","Mar","Apr","May","Jun",
                            "Jul","Aug","Sep","Oct","Nov","Dec"))+
  ggtitle("Cumulative pours over all months")+
  scale_fill_viridis()+
  theme(legend.position = "none")+
  coord_flip()

# Histogram of pours per year
g2 <- y %>% 
  mutate(year=as.factor(substring(x$date.poured,1,4))) %>% 
  filter(!is.na(year)) %>% 
  ggplot(aes(x=year,fill=..count..))+
  geom_histogram(stat="count")+
  ggtitle("Pours per year")+
  scale_fill_viridis()+
  theme(legend.position = "none")+
  theme(axis.text.x = element_text(angle=45,hjust=1))

grid.arrange(g1,g2,ncol=2)
```

Faceting number of pours over the years gives a little more insight as to when pours were occuring.  

```{r}
# Pours per month faceted by year
y %>% 
  mutate(month=as.factor(substring(months.Date(x$date.poured),1,3))) %>% 
  mutate(year=as.factor(substring(x$date.poured,1,4))) %>% 
  filter(!is.na(year)) %>% 
  ggplot(aes(x=month,fill=..count..))+
  geom_histogram(stat="count")+
  scale_x_discrete(limits=c("Jan","Feb","Mar","Apr","May","Jun",
                            "Jul","Aug","Sep","Oct","Nov","Dec"))+
  ggtitle("Pours per month per year")+
  scale_fill_viridis()+
  theme(legend.position = "none")+
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5,size=7))+
  facet_wrap(year~.)
```

## Furnace life
Why are some furnaces lasting longer than others? Dramatically so in some cases? Plotting the longest lasting furnaces (`n > 50`) shows the longest lasting furnace is `toby`, which lasted 178 days. These extremely high values seem like outliers based on experience and when we plot the values using a boxplot, our plot confirms they are outliers.  

```{r}
# barplot of longest lasting furnaces
p1 <- y %>% 
  filter(!is.na(furnace.name)) %>% 
  mutate(furnace.name=as.factor(furnace.name)) %>% 
  count(furnace.name) %>% 
  # arrange(desc(n)) %>% 
  filter(n>50) %>% 
  ggplot(aes(x=reorder(furnace.name,n),y=n,fill=n))+
  geom_bar(stat="identity")+
  coord_flip()+
  scale_fill_viridis()+
  theme(legend.position = "none")+
  ggtitle("Longest lasting furnaces, n>50")

# boxplot of furnace life
p2 <- y %>% 
  filter(!is.na(furnace.name)) %>% 
  mutate(furnace.name=as.factor(furnace.name)) %>% 
  count(furnace.name) %>% 
  select(-furnace.name) %>% 
  mutate(furnace = as.factor("furnace")) %>% 
  ggplot(aes(y=n,x=furnace))+
  geom_boxplot(outlier.shape = NA,
               position=position_dodge(width=.9))+
  geom_jitter(aes(color=n),width=.1)+
  coord_flip()+
  theme(legend.position = "none")+
  ggtitle("Distribution of furnace.life values")

grid.arrange(p1,p2,nrow=1)
```


